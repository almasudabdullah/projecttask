{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d5cab6-515e-4dd6-95ae-6393f0c4435c",
   "metadata": {},
   "source": [
    "## Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8b999-83ba-484a-9b94-f56c201d2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --q unstructured langchain\n",
    "%pip install --q \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e2f74-7c4b-4665-8d87-bc00656f31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy.helpers import bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c0b18-1c06-41a1-a2ca-f9ee23f4f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the PDF\n",
    "local_path = \"Al Aqsa Flood.pdf\"\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faacc1-be29-4d52-a46e-94f5b5b8e728",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394d61f-906b-4776-b8b5-9f0045c76193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk the document\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a39856-0cc0-4ebe-8024-9db32455a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad040e2-3abe-4e23-abb9-951b223b9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb11c92-e732-4a88-8f57-57a19b38e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenSearch\n",
    "client = OpenSearch(hosts=['localhost:9200'])\n",
    "\n",
    "# Create the index for document embeddings\n",
    "client.indices.create(\n",
    "    index=\"rag-document-embeddings\",\n",
    "    body={\n",
    "        \"settings\": {\"index\": {\"knn\": True, \"knn.algo_param.ef_search\": 100}},\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text_vector\": {\n",
    "                    \"type\": \"knn_vector\",\n",
    "                    \"dimension\": 384,  # all-MiniLM-L6-v2 outputs 384-dimensional vectors\n",
    "                    \"method\": {\n",
    "                        \"name\": \"hnsw\",\n",
    "                        \"space_type\": \"cosinesimil\",\n",
    "                        \"engine\": \"lucene\",\n",
    "                        \"parameters\": {\"ef_construction\": 128, \"m\": 24}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }, ignore=400  # Ignore error if index already exists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same HuggingFace embeddings as before\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index document chunks into OpenSearch\n",
    "actions = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    embedding = embeddings.embed_query(chunk.page_content)\n",
    "    action = {\n",
    "        \"_index\": \"rag-document-embeddings\",\n",
    "        \"_id\": i,\n",
    "        \"_source\": {\n",
    "            \"text_vector\": embedding,\n",
    "            \"content\": chunk.page_content\n",
    "        }\n",
    "    }\n",
    "    actions.append(action)\n",
    "\n",
    "bulk(client, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eadf50-2f3d-4420-8858-94e9c1682ffa",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec338c4-f282-462f-b0a0-c1899538eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Hugging Face LLM\n",
    "os.environ['HUGGING_FACE_HUB_API_KEY'] = getpass.getpass('Hugging face api key:')\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=os.environ['HUGGING_FACE_HUB_API_KEY'],\n",
    "    repo_id=repo_id, \n",
    "    model_kwargs={'temperature': 0.2, 'max_length':5000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6ceeb-6883-4688-b923-e771c2b2cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve relevant document chunks\n",
    "def retrieve_chunks(query, k=3):\n",
    "    embedding = embeddings.embed_query(query)\n",
    "    response = client.search(\n",
    "        index=\"rag-document-embeddings\",\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"text_vector\": {\n",
    "                        \"vector\": embedding,\n",
    "                        \"k\": k\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"content\"]  # Only return the content field\n",
    "        }\n",
    "    )\n",
    "    return [hit['_source']['content'] for hit in response['hits']['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436d5cd-5dd0-448c-b5c0-6eddab879c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the multi-query retriever\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Generate five different versions of this question to improve retrieval:\n",
    "    Original question: {question}\"\"\"\n",
    ")\n",
    "\n",
    "def multi_query_retriever(query):\n",
    "    variations = llm.invoke(QUERY_PROMPT.format(question=query)).strip().split('\\n')\n",
    "    all_chunks = []\n",
    "    for var in variations:\n",
    "        all_chunks.extend(retrieve_chunks(var))\n",
    "    return list(set(all_chunks))  # Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e423dc-f632-46f8-9bec-d74cb268ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the RAG chain\n",
    "template = \"\"\"Answer based ONLY on this context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "chain = (\n",
    "    {\"context\": lambda x: \"\\n\\n\".join(multi_query_retriever(x)), \"question\": lambda x: x}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f308f-8472-4506-9517-d79b61d408f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main interaction loop\n",
    "print(\"Welcome! I'm here to answer your questions about 'Al Aqsa Flood'.\")\n",
    "print(\"Type your question and press Enter. Type 'exit' to quit.\\n\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"Your question: \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    try:\n",
    "        response = chain.invoke(query)\n",
    "        print(\"Answer:\", response)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "print(\"\\nThank you for using the RAG system. Goodbye!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
